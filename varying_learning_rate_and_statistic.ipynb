{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Packages\n",
    "import numpy as np\n",
    "\n",
    "from RBM.optimizator.energy_optimizator import Optimizator\n",
    "from RBM.samplings import Samplings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here starts the main program with variable declarations\n",
    "\n",
    "# Number particle \n",
    "Number_particles = 1\n",
    "\n",
    "# Dimension\n",
    "Dimension = 1\n",
    "\n",
    "# Number hidden layer\n",
    "Number_hidden_layer = 1\n",
    "\n",
    "# Number Monte Carlos cycles\n",
    "Number_MC_cycles = 5*10**4\n",
    "\n",
    "# Type algorithm\n",
    "#Algorithm = 'Metropolis'    \n",
    "Algorithm = 'MetropolisHastings'\n",
    "\n",
    "# Interaction\n",
    "Interaction = False\n",
    "\n",
    "# Instantce class Optimizator\n",
    "algorithm_1= Optimizator(Number_particles, Dimension, Number_hidden_layer, Interaction, Algorithm = Algorithm, Number_MC_cycles = Number_MC_cycles) \n",
    "\n",
    "# Instantce class Samplings\n",
    "algorithms = Samplings(Number_particles,Dimension,Number_hidden_layer,Interaction,Algorithm= Algorithm,Number_MC_cycles= Number_MC_cycles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.001\n",
      "good gradient\n",
      "good samplings\n",
      "0.161\n",
      "good gradient\n",
      "good samplings\n",
      "0.321\n",
      "good gradient\n",
      "good samplings\n",
      "0.48\n",
      "good gradient\n",
      "good samplings\n",
      "0.64\n",
      "good gradient\n",
      "good samplings\n",
      "0.8\n",
      "good gradient\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "math domain error",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31m_RemoteTraceback\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;31m_RemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"/home/luis/.local/lib/python3.10/site-packages/joblib/externals/loky/process_executor.py\", line 463, in _process_worker\n    r = call_item()\n  File \"/home/luis/.local/lib/python3.10/site-packages/joblib/externals/loky/process_executor.py\", line 291, in __call__\n    return self.fn(*self.args, **self.kwargs)\n  File \"/home/luis/.local/lib/python3.10/site-packages/joblib/parallel.py\", line 589, in __call__\n    return [func(*args, **kwargs)\n  File \"/home/luis/.local/lib/python3.10/site-packages/joblib/parallel.py\", line 589, in <listcomp>\n    return [func(*args, **kwargs)\n  File \"/home/luis/Downloads/University/Computational_Physics 2_Quantum_Mechanical _Systems/Classes/code-ipynb/project_2/RBM/algorithms/metropolis_hastings.py\", line 205, in metropolis_hastings_algorithm\n    error = sqrt(variance/Number_MC_cycles)\nValueError: math domain error\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 50\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;66;03m# Calculate the sampling after finding the optimal parameter \u001b[39;00m\n\u001b[1;32m     49\u001b[0m Optimal_parameter_a_b_w \u001b[38;5;241m=\u001b[39m (Optimal_parameter_a,Optimal_parameter_b,Optimal_parameter_w) \n\u001b[0;32m---> 50\u001b[0m samplings \u001b[38;5;241m=\u001b[39m \u001b[43malgorithms\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msamplings\u001b[49m\u001b[43m(\u001b[49m\u001b[43mOptimal_parameter_a_b_w\u001b[49m\u001b[43m,\u001b[49m\u001b[43mNumber_samplings\u001b[49m\u001b[43m,\u001b[49m\u001b[43mNumber_core\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgood samplings\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     52\u001b[0m \u001b[38;5;66;03m# Save all output\u001b[39;00m\n",
      "File \u001b[0;32m~/Downloads/University/Computational_Physics 2_Quantum_Mechanical _Systems/Classes/code-ipynb/project_2/RBM/samplings.py:65\u001b[0m, in \u001b[0;36mSamplings.samplings\u001b[0;34m(self, Optimal_parameter_a_b_w, Number_samplings, Number_core)\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[1;32m     63\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m< ERROR > : The Optimal_parameter_a_b_w \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mOptimal_parameter_a_b_w\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m has to be a tuple Optimal_parameter_a_b_w = (a,b,w)\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 65\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mNumber_core\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43malgorithm\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43mb\u001b[49m\u001b[43m,\u001b[49m\u001b[43mw\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mNs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mNumber_samplings\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     67\u001b[0m result \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(result)\n\u001b[1;32m     69\u001b[0m Energies \u001b[38;5;241m=\u001b[39m result[:,\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/joblib/parallel.py:1952\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1946\u001b[0m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[1;32m   1947\u001b[0m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[1;32m   1948\u001b[0m \u001b[38;5;66;03m# reach the first `yield` statement. This starts the aynchronous\u001b[39;00m\n\u001b[1;32m   1949\u001b[0m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[1;32m   1950\u001b[0m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[0;32m-> 1952\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/joblib/parallel.py:1595\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[0;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[1;32m   1592\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[1;32m   1594\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[0;32m-> 1595\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retrieve()\n\u001b[1;32m   1597\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[1;32m   1598\u001b[0m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[1;32m   1599\u001b[0m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[1;32m   1600\u001b[0m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[1;32m   1601\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/joblib/parallel.py:1699\u001b[0m, in \u001b[0;36mParallel._retrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1692\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wait_retrieval():\n\u001b[1;32m   1693\u001b[0m \n\u001b[1;32m   1694\u001b[0m     \u001b[38;5;66;03m# If the callback thread of a worker has signaled that its task\u001b[39;00m\n\u001b[1;32m   1695\u001b[0m     \u001b[38;5;66;03m# triggered an exception, or if the retrieval loop has raised an\u001b[39;00m\n\u001b[1;32m   1696\u001b[0m     \u001b[38;5;66;03m# exception (e.g. `GeneratorExit`), exit the loop and surface the\u001b[39;00m\n\u001b[1;32m   1697\u001b[0m     \u001b[38;5;66;03m# worker traceback.\u001b[39;00m\n\u001b[1;32m   1698\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_aborting:\n\u001b[0;32m-> 1699\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raise_error_fast\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1700\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m   1702\u001b[0m     \u001b[38;5;66;03m# If the next job is not ready for retrieval yet, we just wait for\u001b[39;00m\n\u001b[1;32m   1703\u001b[0m     \u001b[38;5;66;03m# async callbacks to progress.\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/joblib/parallel.py:1734\u001b[0m, in \u001b[0;36mParallel._raise_error_fast\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1730\u001b[0m \u001b[38;5;66;03m# If this error job exists, immediatly raise the error by\u001b[39;00m\n\u001b[1;32m   1731\u001b[0m \u001b[38;5;66;03m# calling get_result. This job might not exists if abort has been\u001b[39;00m\n\u001b[1;32m   1732\u001b[0m \u001b[38;5;66;03m# called directly or if the generator is gc'ed.\u001b[39;00m\n\u001b[1;32m   1733\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m error_job \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1734\u001b[0m     \u001b[43merror_job\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_result\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/joblib/parallel.py:736\u001b[0m, in \u001b[0;36mBatchCompletionCallBack.get_result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    730\u001b[0m backend \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparallel\u001b[38;5;241m.\u001b[39m_backend\n\u001b[1;32m    732\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m backend\u001b[38;5;241m.\u001b[39msupports_retrieve_callback:\n\u001b[1;32m    733\u001b[0m     \u001b[38;5;66;03m# We assume that the result has already been retrieved by the\u001b[39;00m\n\u001b[1;32m    734\u001b[0m     \u001b[38;5;66;03m# callback thread, and is stored internally. It's just waiting to\u001b[39;00m\n\u001b[1;32m    735\u001b[0m     \u001b[38;5;66;03m# be returned.\u001b[39;00m\n\u001b[0;32m--> 736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_return_or_raise\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    738\u001b[0m \u001b[38;5;66;03m# For other backends, the main thread needs to run the retrieval step.\u001b[39;00m\n\u001b[1;32m    739\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/joblib/parallel.py:754\u001b[0m, in \u001b[0;36mBatchCompletionCallBack._return_or_raise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    752\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    753\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m==\u001b[39m TASK_ERROR:\n\u001b[0;32m--> 754\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result\n\u001b[1;32m    755\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result\n\u001b[1;32m    756\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "\u001b[0;31mValueError\u001b[0m: math domain error"
     ]
    }
   ],
   "source": [
    "# Packages \n",
    "from RBM.utils.path_save_output import SaveOutput\n",
    "\n",
    "# Name where will be saving outputs  (file or figure)\n",
    "save = SaveOutput(f'Result_varying_learning_rate_{Algorithm}_interaction_{Interaction}') \n",
    "\n",
    "# Decide to save output  \n",
    "SAVE_OUTPUT = False\n",
    "\n",
    "# Maximum the iterations (The best option it is a power 2 if you would like to do the stadistic analysis with blocking)\n",
    "Maximum_iterations = 100\n",
    "\n",
    "# Number samplings (The best option it is a power 2 if you would like to do the stadistic analysis with blocking)\n",
    "Number_samplings = 2**10\n",
    "\n",
    "# Number core (take care how many core has your computer)\n",
    "Number_core = 8\n",
    "\n",
    "# Different trying with learning rate \n",
    "Low = 0.001\n",
    "High = 0.8\n",
    "Number_trying_learning_rate = 6\n",
    "learning_rate_range = np.linspace(Low,High,Number_trying_learning_rate)\n",
    "\n",
    "# Set up the number decimal \n",
    "learning_rate_range = np.around(learning_rate_range,3)\n",
    "\n",
    "# Saves output \n",
    "Energies_trying_learning_rate = []\n",
    "Optimal_parameter_a_learning_rate =[]\n",
    "Optimal_parameter_b_learning_rate =[]\n",
    "Optimal_parameter_w_learning_rate =[]\n",
    "\n",
    "# Save the output (energy) for each sampling\n",
    "Energies_samplings_save = []\n",
    "\n",
    "# Trying the diffferent learning rate \n",
    "for  learning_rate in learning_rate_range:\n",
    "    print(learning_rate)\n",
    "    Energies, Optimal_parameter_a, Optimal_parameter_b, Optimal_parameter_w, Iteration_number, Time_CPU = algorithm_1.gradient_descent(learning_rate, Maximum_iterations)\n",
    "    print('good gradient')\n",
    "    # Save all output\n",
    "    Energies_trying_learning_rate.append(Energies) \n",
    "    Optimal_parameter_a_learning_rate.append(Optimal_parameter_a)\n",
    "    Optimal_parameter_b_learning_rate.append(Optimal_parameter_b)\n",
    "    Optimal_parameter_w_learning_rate.append(Optimal_parameter_w)\n",
    "    \n",
    "    # Calculate the sampling after finding the optimal parameter \n",
    "    Optimal_parameter_a_b_w = (Optimal_parameter_a,Optimal_parameter_b,Optimal_parameter_w) \n",
    "    samplings = algorithms.samplings(Optimal_parameter_a_b_w,Number_samplings,Number_core)\n",
    "    print('good samplings')\n",
    "    # Save all output\n",
    "    Energies_sampling, Variances_sampling, Errors_sampling, Time_CPU_sam = samplings\n",
    "    Energies_samplings_save.append(Energies_sampling)\n",
    "\n",
    "\n",
    "# Saves or does not save the output (format .dat one for each learning rate)\n",
    "if SAVE_OUTPUT == True :\n",
    "    # Just to saves ther energies output for each learning rate in a external file\n",
    "    for  i in range(len(Energies_trying_learning_rate)):\n",
    "        outfile = open(save.data_path( f'energies_with_learning_rate_{learning_rate_range[i]}' +'.dat'),'w')\n",
    "        outfile.write(f'# Energies, lerning rate {learning_rate_range[i]}:\\n')\n",
    "        for j in range(len(Energies)):\n",
    "            outfile.write('%f \\n' %(Energies_trying_learning_rate[i][j]))\n",
    "        outfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistic analysis with blocking\n",
    "from RBM.statistical_techniques.statistics import StatisticalTechniques\n",
    "\n",
    "# Using blocking \n",
    "blocking_techniques = StatisticalTechniques().blocking\n",
    "\n",
    "# Using bootstrap\n",
    "bootstrap_techniques = StatisticalTechniques().bootstrap\n",
    "\n",
    "for i in range(len(Energies_samplings_save)):\n",
    "    print(f'learning rate {learning_rate_range[i]}')\n",
    "    print('===============================================')\n",
    "    blocking_techniques(Energies_samplings_save[i])\n",
    "    print('===============================================')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Packages\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# Decide to save output  \n",
    "SAVE_OUTPUT = True\n",
    "\n",
    "# Plot the energies vs the number iteration for each learning rate\n",
    "fig = plt.figure(figsize=(15,10))\n",
    "for i in range(len(Energies_trying_learning_rate)): \n",
    "    plt.plot(Iteration_number, Energies_trying_learning_rate[i], label= f'$\\gamma = ${learning_rate_range[i]}')\n",
    "    plt.xlabel(\"Iterations\")\n",
    "    plt.ylabel(\"$<$E$_{L}$$>$\")\n",
    "    plt.title(\"Energies as funtion number iterations\")\n",
    "    \n",
    "   \n",
    "\n",
    "# The exact solution     \n",
    "#plt.axhline(y = 0.5, color = 'r', linestyle = 'dashed', label = 'Exact')\n",
    "\n",
    "# Saves or does not save the output\n",
    "if SAVE_OUTPUT == True:\n",
    "    plt.savefig(save.figure_path(f'energies_vs_learning_rate_{Number_particles}p_{Dimension}D_{Number_hidden_layer}H') + \".png\", format='png',dpi= 800 )\n",
    "plt.legend(bbox_to_anchor=(1.0, 1), loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# Plot the energies vs the number iteration for each learning rate (doing a zoom)\n",
    "fig = plt.figure(figsize=(15,10))\n",
    "for i in range(len(Energies_trying_learning_rate)): \n",
    "    plt.plot(Iteration_number, Energies_trying_learning_rate[i], label= f'$\\gamma = ${learning_rate_range[i]}')\n",
    "    plt.xlabel(\"Iterations\")\n",
    "    plt.ylabel(\"$<$E$_{L}$$>$\")\n",
    "    plt.title(\"Energies as funtion number iterations\")\n",
    "    \n",
    "   \n",
    "\n",
    "# The exact solution     \n",
    "#plt.axhline(y = 0.5, color = 'r', linestyle = 'dashed', label = 'Exact')\n",
    "plt.legend(bbox_to_anchor=(1.0, 1), loc='upper left')\n",
    "\n",
    "# Change the limit to do a zoom\n",
    "plt.ylim(0.4999999,0.5000001)\n",
    "plt.xlim(20,60)\n",
    "\n",
    "# Saves or does not save the output\n",
    "if SAVE_OUTPUT == True:\n",
    "    plt.savefig(save.figure_path(f'energies_vs_learning_rate_zoom_{Number_particles}p_{Dimension}D_{Number_hidden_layer}H') + \".png\", format='png',dpi= 800 )\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save and Plot the data using panda "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "\n",
    "# Name where will be saving outputs  (file or figure)\n",
    "save_sampling = SaveOutput(f'Result_samplings_{Algorithm}_interaction_{Interaction}') \n",
    "\n",
    "# Saves all output using pandas \n",
    "data_varing_learning_rate = {}\n",
    "data_samplings = {} \n",
    "for i in range(len(Energies_trying_learning_rate)):\n",
    "    data_varing_learning_rate[f'Energies wirh learning rate: {learning_rate_range[i]}'] = Energies_trying_learning_rate[i]\n",
    "    data_samplings[f'Energies wirh learning rate: {learning_rate_range[i]}'] = Energies_samplings_save[i]\n",
    "\n",
    "# Nice panda viw of the data\n",
    "Nice_panda_view_learning_rate = pd.DataFrame(data_varing_learning_rate)\n",
    "\n",
    "Nice_panda_view_samplings = pd.DataFrame(data_samplings)\n",
    "\n",
    "\n",
    "# Decide to save output  \n",
    "SAVE_OUTPUT = True\n",
    "\n",
    "# Saves or does not save the output\n",
    "if SAVE_OUTPUT == True:\n",
    "    # Save a external file in .csv format using panda\n",
    "    Nice_panda_view_learning_rate.to_csv(save.data_path(f'energies_vs_learning_rate_{Number_particles}p_{Dimension}d_{Number_hidden_layer}h.csv'), index=True)\n",
    "    Nice_panda_view_samplings.to_csv(save_sampling.data_path(f'energies_samplings_{Number_particles}p_{Dimension}d_{Number_hidden_layer}h.csv'), index=True)\n",
    "\n",
    "# Read the external .csv data format with pandas  \n",
    "save_output = pd.read_csv(save.data_path(f'energies_vs_learning_rate_{Number_particles}p_{Dimension}d_{Number_hidden_layer}h.csv'))\n",
    "\n",
    "# Choose one of the data \n",
    "Energies_learninf_rate_1 = save_output[f'Energies wirh learning rate: {learning_rate_range[i]}']\n",
    "\n",
    "# Transform to numpy class\n",
    "save_output_numpy = np.array(save_output)\n",
    "\n",
    "#print(save_output_numpy[:,0])\n",
    "\n",
    "# Print nice view\n",
    "Nice_panda_view_learning_rate\n",
    "\n",
    "Nice_panda_view_samplings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Packages\n",
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# Decide to save output  \n",
    "SAVE_OUTPUT = False\n",
    "\n",
    "# ID data has to be in .csv format\n",
    "ID_data = '/home/luis/Downloads/University/Computational_Physics 2_Quantum_Mechanical _Systems/Classes/code-ipynb/project_2/Result_varying_learning_rate_MetropolisHastings/DataFile/energies_vs_learning_rate_1p_1d_1h.csv'\n",
    "\n",
    "# Read the external .csv data format with pandas  \n",
    "save_output = pd.read_csv(ID_data)\n",
    "\n",
    "# Transform to numpy class\n",
    "save_output_numpy = np.array(save_output)\n",
    "\n",
    "# Different trying learning rate \n",
    "Low = 0.001\n",
    "High = 0.8\n",
    "Number_trying_learning_rate = 10\n",
    "learning_rate_range = np.linspace(Low,High,Number_trying_learning_rate)\n",
    "\n",
    "# Set up the number decimal \n",
    "learning_rate_range = np.around(learning_rate_range,3)\n",
    "\n",
    "# Plot the energies vs the number iteration for each learning rate using information saved  \n",
    "fig = plt.figure(figsize=(15,10))\n",
    "for i in range(0,len(learning_rate_range)): \n",
    "    plt.plot(save_output_numpy[:,0], save_output_numpy[:,i+1], label= f'$\\gamma = ${learning_rate_range[i]}')\n",
    "    plt.xlabel(\"Iterations\")\n",
    "    plt.ylabel(\"$<$E$_{L}$$>$\")\n",
    "    plt.title(\"Energies as funtion number iterations\")\n",
    "    \n",
    "   \n",
    "\n",
    "# The exact solution     \n",
    "plt.axhline(y = 0.5, color = 'r', linestyle = 'dashed', label = 'Exact')\n",
    "\n",
    "# Saves or does not save the output\n",
    "if SAVE_OUTPUT == True:\n",
    "    plt.savefig(save.figure_path(f'energies_vs_learning_rate_{Number_particles}p_{Dimension}D_{Number_hidden_layer}H') + \".png\", format='png',dpi= 800 )\n",
    "plt.legend(bbox_to_anchor=(1.0, 1), loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# Plot the energies vs the number iteration for each learning rate (doing a zoom)\n",
    "fig = plt.figure(figsize=(15,10))\n",
    "for i in range(0,len(learning_rate_range)): \n",
    "    plt.plot(save_output_numpy[:,0], save_output_numpy[:,i+1], label= f'$\\gamma = ${learning_rate_range[i]}')\n",
    "    plt.xlabel(\"Iterations\")\n",
    "    plt.ylabel(\"$<$E$_{L}$$>$\")\n",
    "    plt.title(\"Energies as funtion number iterations\")\n",
    "    \n",
    "   \n",
    "\n",
    "# The exact solution     \n",
    "plt.axhline(y = 0.5, color = 'r', linestyle = 'dashed', label = 'Exact')\n",
    "plt.legend(bbox_to_anchor=(1.0, 1), loc='upper left')\n",
    "\n",
    "# Change the limit to do a zoom\n",
    "plt.ylim(0.4999,0.5001)\n",
    "plt.xlim(30,60)\n",
    "\n",
    "# Saves or does not save the output\n",
    "if SAVE_OUTPUT == True:\n",
    "    plt.savefig(save.figure_path(f'energies_vs_learning_rate_zoom_{Number_particles}p_{Dimension}D_{Number_hidden_layer}H') + \".png\", format='png',dpi= 800 )\n",
    "plt.show()\n",
    "\n",
    "# Print a nice view with pandas \n",
    "save_output"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
